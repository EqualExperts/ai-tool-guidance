# ChatGPT - Detailed Guidance
*(Generated by AI, ChatGPT Deep Research, on April 1st 2025)*

## 1. Tool Overview

ChatGPT is an AI chatbot service developed by OpenAI, accessible through a web interface at **chatgpt.com**. It uses large language models (notably GPT-3.5 and GPT-4) to generate conversational responses and assist with tasks in natural language ([ChatGPT | OpenAI](https://openai.com/chatgpt/overview/#:~:text=Get%20answers,more%20productive)). Users can ask questions or request help with writing, coding, brainstorming, and more, and ChatGPT will produce relevant answers or creative content.

**Plans:** ChatGPT is offered in several tiers to cater to different needs ([ChatGPT Pricing | OpenAI](https://openai.com/chatgpt/pricing/#:~:text=Get%20Free)):

- **Free Plan:** Provides basic access to ChatGPT at no cost. Free users can chat with the AI using the default model (GPT-3.5) and have a limited feature set and rate limits ([ChatGPT | OpenAI](https://openai.com/chatgpt/overview/#:~:text=Get%20answers,more%20productive)). This tier is suitable for casual use and learning, though it lacks the advanced capabilities of paid plans.
- **ChatGPT Plus:** A paid subscription (US$20 per month) for individuals that unlocks enhanced features ([ChatGPT Pricing | OpenAI](https://openai.com/chatgpt/pricing/#:~:text=)). Plus users get general access even during peak times, faster response speeds, and the ability to use OpenAI’s more powerful GPT-4 model for better quality outputs ([ChatGPT Pricing | OpenAI](https://openai.com/chatgpt/pricing/#:~:text=Plan%3A%20Plus%2C%20Feature%3A%20GPT,preview%2C%20Yes)). Plus also includes access to new beta features (e.g. code analysis tools, image generation) as they are rolled out.
- **ChatGPT Team:** A plan for teams or small organisations, priced at about US$25 per user per month (annual billing) ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=)). It includes *everything in Plus* with additional collaboration and admin features. Team accounts share a dedicated workspace with centralized billing and user management tools ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=Easily%20manage%20your%20account)). This tier offers higher usage limits than Plus and lets team members share content or custom ChatGPT-powered tools securely within the organisation ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=Get%20started%20with%20ChatGPT%20Team,today)) ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=,more%20connectors%20coming%20soon)).
- **ChatGPT Enterprise:** An enterprise-grade offering for companies and institutions. It has all Team features and further enhancements: unlimited use of GPT-4 with a larger context window (for longer inputs) ([Introducing ChatGPT Enterprise | Sandro Gianella - LinkedIn](https://www.linkedin.com/posts/sandrogianella_introducing-chatgpt-enterprise-activity-7101998252727619585-71Gy#:~:text=LinkedIn%20www,to%20process%20four%20times)), higher message throughput, and advanced admin and security integrations. Enterprise plans include dedicated support and are negotiated via a contract (OpenAI provides *Contact Sales* for pricing) ([ChatGPT Pricing | OpenAI](https://openai.com/chatgpt/pricing/#:~:text=,management)). This tier is designed to meet robust security, privacy, and compliance requirements of larger organisations.

Across all plans, the core service remains a conversational AI tool available via web browser (and also mobile apps, though this report focuses on the web tool). The official website for accessing ChatGPT is **[chatgpt.com](https://chatgpt.com)**, and OpenAI’s homepage provides additional product information ([ChatGPT | OpenAI](https://openai.com/chatgpt/overview/#:~:text=Get%20answers,more%20productive)).

## 2. Privacy Settings

ChatGPT provides user-configurable privacy controls in its web interface to help individuals manage their data. Key privacy-related settings include:

- **Chat History & Training Toggle:** Users can disable chat history to prevent their conversations from being used to train OpenAI’s models ([Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq#:~:text=Our%20large%20language%20models%20are,you%20choose%20to%20disable%20training)) ([Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq#:~:text=To%20disable%20model%20training%2C%20navigate,train%20and%20improve%20our%20models)). This setting, labeled *“Improve the model for everyone”*, can be toggled off in **Settings > Data Controls**. When turned off, new conversations are not stored in the account’s history for long-term use in model improvement.
- **Temporary Chat Mode:** When chat history is disabled (or when using a *Temporary Chat* session), ChatGPT treats those conversations as ephemeral ([Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq#:~:text=If%20I%E2%80%99m%20having%20a%20Temporary,memories%20to%20enable%20it%20for)). Such chats will not appear in the persistent sidebar history and **will be deleted from OpenAI’s systems after 30 days**, with retention only for abuse monitoring before deletion ([Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq#:~:text=Temporary%20Chats%20are%20deleted%20from,you%20have%20not%20opted%20out)). In other words, turning off history gives users a privacy safeguard: past messages won’t be visible later and won’t feed into training data ([Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq#:~:text=If%20I%E2%80%99m%20having%20a%20Temporary,memories%20to%20enable%20it%20for)). (Even with history off, OpenAI may briefly retain the data internally up to 30 days for security purposes, then purge it ([Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq#:~:text=Temporary%20Chats%20are%20deleted%20from,you%20have%20not%20opted%20out)).)
- **Data Export:** Users can export their ChatGPT data at any time. In **Settings > Data Controls**, an *Export Data* option allows users to request a downloadable file containing their conversation history and other account data ([Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq#:~:text=How%20do%20I%20export%20my,data%20from%20ChatGPT)). This helps users review what information ChatGPT has stored and is useful for record-keeping or moving data.
- **Account Deletion:** OpenAI provides an option to delete a ChatGPT account (and associated data) through the settings as well ([Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq#:~:text=How%20do%20I%20delete%20my,ChatGPT%20account)). Deletion is irreversible and will remove personal data and chat histories from OpenAI’s systems (except data which the company may need to retain for legal reasons). This gives users control to fully remove their data if they decide to stop using the service.

By default, for free and Plus users, ChatGPT conversation data *may* be used by OpenAI to improve the model ([Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq#:~:text=Our%20large%20language%20models%20are,you%20choose%20to%20disable%20training)). OpenAI’s policy is that *ChatGPT improves by further training on the conversations people have with it, unless you choose to disable training* ([Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq#:~:text=Our%20large%20language%20models%20are,you%20choose%20to%20disable%20training)). This means users handling sensitive information should proactively use the privacy settings (as above) to opt out of such data usage. 

It’s worth noting that in the Team and Enterprise plans, OpenAI **automatically excludes user data from model training by default** ([ChatGPT Pricing | OpenAI](https://openai.com/chatgpt/pricing/#:~:text=,admin%20console%20and%20unified%20billing)) ([ChatGPT Pricing | OpenAI](https://openai.com/chatgpt/pricing/#:~:text=uploads%2C%20data%20analysis%2C%20and%20search)). In those plans, the organisation’s data is treated as “business data” and not used to train OpenAI’s models, aligning with enterprise privacy expectations. However, individual users on those plans still retain the ability to manage their own chat history (e.g. they can delete or export conversations) just as in the free interface ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=What%20is%20OpenAI%E2%80%99s%20policy%20on,data%20retention%20for%20ChatGPT%20Team)).

Overall, ChatGPT’s web tool offers clear privacy controls and transparency features. The **Privacy Policy** (linked in the interface footer) further explains data practices, and users are prompted to agree to terms and acknowledge the privacy policy when they first use the service ([ChatGPT](https://chatgpt.com/#team-pricing#:~:text=Voice)).

## 3. Terms of Use and Privacy Policy

OpenAI publishes **Terms of Use** and a **Privacy Policy** that govern use of ChatGPT. These documents are accessible via OpenAI’s website and are linked at the bottom of the ChatGPT web interface ([ChatGPT](https://chatgpt.com/#team-pricing#:~:text=Voice)). Key points include:

- **Terms of Use:** The ChatGPT *Terms of Use* outline the rules and conditions for using the service. (Notably, OpenAI has separate terms for consumer usage and for business usage.) The standard Terms of Use, updated as of December 11, 2024, apply to individual users of ChatGPT, DALL·E, and other OpenAI services ([Terms of use | OpenAI](https://openai.com/policies/row-terms-of-use/#:~:text=Thank%20you%20for%20using%20OpenAI%21)). They cover account requirements (e.g. age restrictions) ([Terms of use | OpenAI](https://openai.com/policies/row-terms-of-use/#:~:text=Minimum%20age,permission%20to%20use%20the%20Services)), acceptable use policies, intellectual property, and disclaimers. For instance, the terms clarify that by using the service, users agree not to input illegal or harmful content and that OpenAI may terminate accounts that violate policies. The terms also include an arbitration clause for dispute resolution in some jurisdictions ([Terms of use | OpenAI](https://openai.com/policies/row-terms-of-use/#:~:text=These%20Terms%20of%20Use%20apply,you%20agree%20to%20these%20Terms)). Importantly for UK users, OpenAI provides a UK/EEA-specific terms document that aligns with local legal requirements ([Terms of use | OpenAI](https://openai.com/policies/row-terms-of-use/#:~:text=If%20you%20reside%20in%20the,governed%20by%20these%20terms%20%E2%81%A0)), but the content is largely similar in substance to the global terms.

- **Business Terms:** For organisational use (ChatGPT Team or Enterprise), OpenAI has dedicated *Business Terms*. These govern the use of ChatGPT in a business context and take precedence for those subscriptions ([Business terms | OpenAI](https://openai.com/policies/business-terms/#:~:text=These%20OpenAI%20Business%20Terms%20govern,the%20Terms%20of%20use%20%E2%81%A0)). The Business Terms (last updated Nov 14, 2023) cover additional provisions relevant to companies, such as confidentiality commitments, liability limits appropriate for enterprise contracts, and data processing assurances. For example, these terms incorporate data protection agreements to help organisations comply with laws like GDPR. Government agencies considering ChatGPT Enterprise would review and sign these Business Terms (often alongside a Data Processing Addendum) rather than just the standard consumer terms.

- **Privacy Policy:** OpenAI’s Privacy Policy (last updated July 2023, as indicated on the policy page) explains what personal data is collected and how it is used ([Terms of use | OpenAI](https://openai.com/policies/row-terms-of-use/#:~:text=Our%20Privacy%20Policy%20%E2%81%A0%20explains,is%20an%20important%20document%20that)). It details the types of information ChatGPT may gather (account details, conversations, usage logs, etc.), the purposes (e.g. providing the service, research and model improvement, security monitoring), and how users can exercise data rights. Notably for government use, the Privacy Policy states that **users retain ownership of their inputs and outputs**: OpenAI does not claim intellectual property over the content users provide or receive ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Who%20owns%20inputs%20and%20outputs%3F)). OpenAI only asks for a limited license to use the data for operating the service (and if applicable, improving the model unless opted out) ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=As%20between%20you%20and%20OpenAI%3A,law%2C%20and%20enforce%20our%20policies)). The policy also describes that personal data may be processed in the United States and other countries where OpenAI or its service providers operate, with safeguards in place for international transfers. It commits to compliance with privacy laws like GDPR and outlines how users can contact OpenAI or exercise rights (such as deletion or access to data).

**Key considerations for government use:** The OpenAI terms emphasize that users (or organisations) **own the content** they put into and get out of ChatGPT ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Who%20owns%20inputs%20and%20outputs%3F)), which is crucial for intellectual property and confidentiality in a government context. However, the terms also make clear that OpenAI may review or retain data in certain cases (for instance, for abuse prevention or if required by law) ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Who%20can%20view%20conversations%20and,chat%20history%20in%20ChatGPT%20Team)). Government users should be aware that using ChatGPT (especially the free/Plus versions) involves trusting OpenAI as a data processor. Agencies will likely want to utilize the Business Terms and a formal Data Processing Addendum to ensure compliance with public sector data policies. OpenAI has indicated willingness to sign such DPAs for ChatGPT Team and Enterprise customers to meet GDPR requirements ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Can%20OpenAI%20support%20my%20compliance,GDPR%20and%20other%20privacy%20laws)).

In summary, the current Terms of Use and Privacy Policy are readily available for review on OpenAI’s website (see: **OpenAI Terms of Use** ([Terms of use | OpenAI](https://openai.com/policies/row-terms-of-use/#:~:text=Thank%20you%20for%20using%20OpenAI%21)) and **OpenAI Privacy Policy** ([Terms of use | OpenAI](https://openai.com/policies/row-terms-of-use/#:~:text=Our%20Privacy%20Policy%20%E2%81%A0%20explains,is%20an%20important%20document%20that))). Government practitioners should review these documents closely to identify any clauses on liability, data use, or security that would impact public sector adoption, and engage with OpenAI’s sales/legal team via the Enterprise agreement for any necessary modifications or clarifications.

## 4. Data Management

Data management covers how ChatGPT handles user data across its lifecycle – where data is stored, how it is protected in transit and at rest, and how long it is kept. The considerations below are especially pertinent to UK government use, where data security and sovereignty are paramount.

### 4.1 Server Location and Data Residency

By default, ChatGPT user data (conversation content and account info) is stored on OpenAI’s servers in the **United States**. OpenAI’s infrastructure is hosted on cloud data centers (leveraging partners such as Microsoft Azure) largely in U.S. regions for its general service. This means that without special arrangements, prompts and responses from UK users would be transmitted to and stored in servers under U.S. jurisdiction. For many users this is acceptable under standard contractual clauses, but government agencies often have stricter data residency requirements.

**European Data Residency:** In February 2025, OpenAI announced a new data residency option for ChatGPT aimed at European customers ([OpenAI launches data residency in Europe | TechCrunch](https://techcrunch.com/2025/02/06/openai-launches-data-residency-in-europe/#:~:text=OpenAI%20on%20Thursday%20launched%20data,using%20the%20AI%20company%E2%80%99s%20products)). New ChatGPT Enterprise (and ChatGPT Education) workspaces can now choose to have customer content **stored at rest in Europe** rather than the US ([OpenAI launches data residency in Europe | TechCrunch](https://techcrunch.com/2025/02/06/openai-launches-data-residency-in-europe/#:~:text=Beginning%20Thursday%2C%20OpenAI%20customers%20using,between%20networks%20or%20being%20accessed)). With this feature enabled, any conversations, prompts, uploaded files, images, and custom GPTs from those users will be stored on servers located in Europe ([OpenAI launches data residency in Europe | TechCrunch](https://techcrunch.com/2025/02/06/openai-launches-data-residency-in-europe/#:~:text=OpenAI%20says%20that%2C%20with%20European,in%20the%20region%2C%20per%20OpenAI)). This helps organisations comply with European data sovereignty laws such as GDPR, Germany’s BDSG, and the UK’s Data Protection Act ([OpenAI launches data residency in Europe | TechCrunch](https://techcrunch.com/2025/02/06/openai-launches-data-residency-in-europe/#:~:text=the%20AI%20company%E2%80%99s%20products)). In practice, a UK government department could opt for a ChatGPT Enterprise tenant with EU/UK residency to ensure that the data remains within European legal jurisdiction.

It’s important to note that the European residency option is currently available for **Enterprise and Edu** customers (and certain API projects) – it is not available for the Free, Plus, or Team plans as of early 2025 ([OpenAI launches data residency in Europe | TechCrunch](https://techcrunch.com/2025/02/06/openai-launches-data-residency-in-europe/#:~:text=Beginning%20Thursday%2C%20OpenAI%20customers%20using,between%20networks%20or%20being%20accessed)). Additionally, OpenAI has stated this can only be configured for new Enterprise projects at the moment (existing projects cannot be retrofitted to EU-only storage) ([OpenAI launches data residency in Europe | TechCrunch](https://techcrunch.com/2025/02/06/openai-launches-data-residency-in-europe/#:~:text=OpenAI%20notes%20that%2C%20as%20of,updated%20to%20have%20European%20residency)). We can expect OpenAI to expand regional options over time (with potential future regions beyond Europe), but currently European storage is the main offering for data residency outside the U.S.

**Implications for UK Government:** From a UK perspective, hosting data in the EU (or specifically in UK-based data centers) is often preferred for sensitive information. While OpenAI doesn’t yet mention a UK-sovereign hosting separate from the broader EU option, the European data residency should satisfy UK GDPR requirements since the UK’s data regime is essentially aligned with EU GDPR standards. Nonetheless, public sector organisations should confirm with OpenAI where exactly in Europe data will reside (e.g. in an EU member state vs. in the UK) and ensure appropriate legal measures (DPA, standard contractual clauses) are in place for any data transfers. As of now, choosing ChatGPT Enterprise with EU residency would keep data storage and processing geographically within Europe’s regulatory zone, mitigating concerns about the U.S. CLOUD Act or other foreign government access to data. OpenAI’s move to offer this option is a response to enterprise demand for local data control, and it signifies progress in making ChatGPT more compliant with European and UK public sector policies ([OpenAI launches data residency in Europe | TechCrunch](https://techcrunch.com/2025/02/06/openai-launches-data-residency-in-europe/#:~:text=the%20AI%20company%E2%80%99s%20products)).

### 4.2 Data in Transit

Data in transit refers to information as it moves over networks — for example, when a user in the UK sends a query to ChatGPT’s servers and receives a response. OpenAI implements standard encryption protocols to protect data during these transfers. All communication between the user’s browser and the ChatGPT service is **encrypted using TLS (Transport Layer Security)**. According to OpenAI, data is encrypted in transit with TLS 1.2 or higher ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=,compliance)). In practical terms, this means that the HTTPS connection you see in the browser (https://chatgpt.com) is secured, and any data you send or receive cannot be easily intercepted or read by third parties on the network.

OpenAI’s backend systems also maintain encryption for data in transit internally. For example, if ChatGPT uses cloud services or needs to communicate between data centers or to content filtering services, those links are encrypted as well ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=How%20does%20OpenAI%20ensure%20data,security)). OpenAI explicitly notes that it encrypts data in transit both *between customers and us and between us and our service providers* ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=How%20does%20OpenAI%20ensure%20data,security)). This end-to-end approach ensures that as your data flows through the ChatGPT pipeline (from your device to OpenAI and any sub-processors), it remains protected by strong cryptographic protocols.

For government users, this level of in-transit encryption aligns with best practices (similar to how GOV.UK services enforce HTTPS). ChatGPT’s TLS encryption helps prevent eavesdropping or tampering with the content of conversations while they traverse the internet. It’s worth confirming that OpenAI supports modern cipher suites and certificates trusted by UK government IT standards, but given their SOC 2 compliance (see Section 7), it’s likely they adhere to industry-standard encryption configurations.

There are currently no options for customer-managed network controls (such as a dedicated private network or on-premise gateway) in ChatGPT’s cloud service – all users connect over the public internet using TLS. Therefore, agencies should treat ChatGPT like any external cloud SaaS service from a network perspective, ensuring that any use of the tool is done over approved secure connections. In summary, **data in transit is well-protected via encryption**, reducing the risk of interception ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=,compliance)). Users must still be cautious about *what* data they send (avoiding highly classified or secret data over any external service), but the transit itself is encrypted to a high standard.

### 4.3 Data at Rest

Data at rest refers to information stored on disk or in databases when it’s not actively being transmitted. In the context of ChatGPT, this includes conversation logs saved on OpenAI’s servers, user account info, and any files or images a user uploads to the ChatGPT interface. OpenAI has implemented measures to secure data at rest across all plan offerings, with enhanced controls for business tiers.

**Encryption at Rest:** OpenAI states that all user data is **encrypted at rest** on their systems, using AES-256 encryption ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=,compliance)). AES-256 is an industry-standard encryption algorithm commonly used to protect data in storage, and is considered strong encryption by UK National Cyber Security Centre standards. This means that if someone somehow accessed the raw storage drives or databases without authorization, the data would not be readable without the proper cryptographic keys. The encryption at rest applies to ChatGPT Team and Enterprise data (as highlighted on those product pages) ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=,compliance)), and we can reasonably assume the same encryption standard is applied to Free and Plus user data as well, given OpenAI’s overarching security practices.

**Data Retention Policies:** How long ChatGPT keeps data and in what form varies by plan and user settings:

- For **individual (Free/Plus) users**, if chat history is enabled, conversations are stored indefinitely in the user’s account history on ChatGPT servers. These stored chats can be used by OpenAI to improve the model (training) unless the user opts out ([Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq#:~:text=Our%20large%20language%20models%20are,you%20choose%20to%20disable%20training)). OpenAI has not published a specific default retention period for users who do not delete their chats; in practice, data may be retained as long as the account exists (to allow users to refer back to past chats) and possibly archived for model training purposes. However, if a user deletes a conversation or their account, OpenAI’s policy is to remove that data from their systems within 30 days unless required for legal reasons ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Each%20of%20your%20end%20users,periods%20may%20compromise%20product%20experience)). Similarly, if a user uses the “temporary chat” (history off) mode for a conversation, that conversation is only stored for up to 30 days before deletion (as discussed in Privacy Settings) ([Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq#:~:text=Temporary%20Chats%20are%20deleted%20from,you%20have%20not%20opted%20out)). In short, free and Plus users have control to prune their data, but otherwise data might persist and be used internally by OpenAI.

- For **ChatGPT Team** (business plan for small orgs), **data is not used for training by default** ([ChatGPT Pricing | OpenAI](https://openai.com/chatgpt/pricing/#:~:text=,admin%20console%20and%20unified%20billing)), which means OpenAI will not utilize those conversations to improve the model. Each end-user on Team still has control over whether their conversations are saved in history or treated as temporary ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=What%20is%20OpenAI%E2%80%99s%20policy%20on,data%20retention%20for%20ChatGPT%20Team)). If a Team user disables history, those chats are ephemeral (30-day retention max, then deletion) just like for free users ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=What%20is%20OpenAI%E2%80%99s%20policy%20on,data%20retention%20for%20ChatGPT%20Team)). If they do not disable history, their chats will remain accessible in their account history. The Team *administrator* does not have direct access to all user chat logs (each user’s history is private to them; see Audit Logging for details) ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Who%20can%20view%20conversations%20and,chat%20history%20in%20ChatGPT%20Team)). Any conversation that is deleted by a Team user will be expunged from OpenAI’s systems within 30 days as well ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Each%20of%20your%20end%20users,periods%20may%20compromise%20product%20experience)). Essentially, ChatGPT Team defers to individual user privacy controls, but assures that whatever is stored is kept private to the user and not repurposed for training. Data at rest for Team is encrypted and protected similarly to other tiers.

- For **ChatGPT Enterprise**, data management is more configurable. By default, **Enterprise user data is excluded from model training** altogether ([ChatGPT Pricing | OpenAI](https://openai.com/chatgpt/pricing/#:~:text=uploads%2C%20data%20analysis%2C%20and%20search)). In addition, *workspace administrators can define custom data retention periods* for their organisation’s ChatGPT instance ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=What%20is%20OpenAI%E2%80%99s%20policy%20on,ChatGPT%20Enterprise%20and%20ChatGPT%20Edu)). This means a government organisation could, for example, set ChatGPT to retain conversation history for only X number of days or months, after which it is automatically deleted, to comply with internal data policies. OpenAI confirms that any deleted conversations in Enterprise will be removed from their systems within 30 days (unless legal obligations require otherwise) ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Your%20workspace%20admins%20control%20how,periods%20may%20compromise%20product%20experience)) ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=What%20is%20OpenAI%E2%80%99s%20policy%20on,ChatGPT%20Enterprise%20and%20ChatGPT%20Edu)). The ability to shorten retention is a critical feature – although OpenAI notes that having very short retention might disable useful features like conversation continuity for users ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Your%20workspace%20admins%20control%20how,periods%20may%20compromise%20product%20experience)). Enterprise customers thus have control to balance usability with compliance by choosing an appropriate retention window. All data at rest in Enterprise is encrypted (AES-256) and can now be stored in the EU region if selected, as discussed above ([OpenAI launches data residency in Europe | TechCrunch](https://techcrunch.com/2025/02/06/openai-launches-data-residency-in-europe/#:~:text=Beginning%20Thursday%2C%20OpenAI%20customers%20using,between%20networks%20or%20being%20accessed)). Enterprise also allows the organisation to export or audit data via API if needed (see Audit Logging). From a security standpoint, Enterprise data at rest enjoys the highest level of oversight: encryption, optional regional storage, and admin-controlled lifecycle.

**Access and Protection:** OpenAI maintains strict internal access controls to data at rest. They state that access to user conversations on their systems is limited to authorized personnel, and only for specific purposes such as debugging issues, preventing abuse, or if required by law ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Who%20can%20view%20conversations%20and,chat%20history%20in%20ChatGPT%20Team)). For example, an OpenAI engineer cannot arbitrarily read conversation logs; such access would only be allowed in scenarios like investigating a bug report or a content policy violation, and even then by authorized staff under confidentiality obligations ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Who%20can%20view%20conversations%20and,chat%20history%20in%20ChatGPT%20Team)). In Enterprise settings, OpenAI further commits that staff will only access conversation data with the customer’s explicit permission (for example, if the customer requests support that requires looking at a specific conversation) or if mandated by applicable law ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Within%20your%20organization%2C%20end%20users,where%20required%20by%20applicable%20law)). These controls, combined with the encryption mentioned earlier, reduce the risk of insider threats or unauthorized disclosure of data stored within ChatGPT.

For government users, data-at-rest policies mean that sensitive information placed into ChatGPT should be carefully governed. While the Enterprise tier offers stronger guarantees (no training usage, custom deletion timelines, and audit capabilities), using the free or Plus service for official data would pose concerns since those tiers could retain data and use it to train models. In any case, **official or sensitive data should only be input into ChatGPT Enterprise with proper agreements in place**, ensuring that data at rest is handled in compliance with government standards (e.g. OFFICIAL data under the UK Government Classification Scheme should at minimum be in an environment with encryption at rest and strict access control, which ChatGPT Enterprise does provide ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=%2A%20Multi)) ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Within%20your%20organization%2C%20end%20users,where%20required%20by%20applicable%20law))).

## 5. Audit Logging

Audit logging is an important feature for many government and enterprise IT environments, as it allows organisations to monitor how a system is used and to detect any improper or unauthorized activities. In the context of ChatGPT:

- **Individual (Free/Plus) Users:** There is no admin audit log in the consumer service, since each account is isolated to a single user. Users can review their own chat history, but there is no mechanism for an external administrator to log or audit another user’s conversations on the free platform. OpenAI itself keeps internal logs for security (e.g. to monitor abuse), but these are not exposed to end-users.

- **ChatGPT Team:** The Team plan introduces a shared workspace, but currently **administrators on a Team** do not have the ability to read through users’ conversations via the ChatGPT interface. According to OpenAI, in ChatGPT Team, only the end users can view their own conversation history; the workspace admin can manage users but **does not by default have access to the content of conversations** for privacy reasons ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Who%20can%20view%20conversations%20and,chat%20history%20in%20ChatGPT%20Team)). Audit logging in the Team plan is therefore limited – an admin might see high-level usage metrics or who is a member of the workspace, but cannot directly audit conversation content unless users export and share it. (OpenAI employees, as noted, might review content if needed for abuse prevention, but that is an internal process ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Who%20can%20view%20conversations%20and,chat%20history%20in%20ChatGPT%20Team)).)

- **ChatGPT Enterprise:** The Enterprise plan offers robust audit logging capabilities to meet corporate and compliance needs. Notably, OpenAI provides an **Enterprise Compliance API** that allows audit access to conversation logs and related metadata ([Compliance API for Enterprise Customers | OpenAI Help Center](https://help.openai.com/en/articles/9261474-compliance-apis-for-enterprise-customers#:~:text=The%20Compliance%20API%20provides%20access,eDiscovery%2C%20DLP%2C%20or%20SIEM%20tools)). Through this API, a workspace administrator can retrieve records of all conversations within their organisation’s ChatGPT Enterprise environment, which can include details such as the text of prompts and responses, timestamps, and which user initiated them. This data can then be integrated with standard enterprise compliance tools – for example, security information and event management (SIEM) systems, data loss prevention (DLP) solutions, or eDiscovery tools ([Compliance API for Enterprise Customers | OpenAI Help Center](https://help.openai.com/en/articles/9261474-compliance-apis-for-enterprise-customers#:~:text=The%20Compliance%20API%20provides%20access,eDiscovery%2C%20DLP%2C%20or%20SIEM%20tools)) ([Compliance API for Enterprise Customers | OpenAI Help Center](https://help.openai.com/en/articles/9261474-compliance-apis-for-enterprise-customers#:~:text=DLP%20,sensitive%20information%20within%20an%20organization)). OpenAI has partnered with leading compliance vendors (like Microsoft Purview, Splunk, etc.) to ensure the logs can be ingested for monitoring and archival ([Compliance API for Enterprise Customers | OpenAI Help Center](https://help.openai.com/en/articles/9261474-compliance-apis-for-enterprise-customers#:~:text=To%20help%20with%20their%20compliance,DLP%29%20companies)). Essentially, the Compliance API acts as an audit log feed, enabling organisations to meet record-keeping requirements and to investigate incidents involving ChatGPT usage.

OpenAI’s documentation confirms that **the Compliance API is available only to Enterprise customers** (it is not provided for Team or lower plans) ([Compliance API for Enterprise Customers | OpenAI Help Center](https://help.openai.com/en/articles/9261474-compliance-apis-for-enterprise-customers#:~:text=How%20to%20get%20access)). Using this API, a government organisation’s IT security team could, for instance, automatically archive all ChatGPT interactions for oversight, or run queries to find if any sensitive keywords were used in prompts, supporting compliance with internal policies. It also helps with legal e-discovery – if there’s a freedom of information request or litigation hold, the agency can retrieve relevant ChatGPT conversation records via the API.

From a compliance perspective, this audit logging feature is crucial. It allows a level of transparency and control: the organisation is not blindly using ChatGPT, but can keep an eye on how it’s being used and ensure it’s within acceptable use. The logs include both conversations and any *custom GPTs* (ChatGPT “custom versions” or bots) that users create in the workspace ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Within%20your%20organization%2C%20end%20users,where%20required%20by%20applicable%20law)). 

To summarise, **ChatGPT Enterprise offers audit logging through the Compliance API, giving admins a log of conversations and usage** ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Within%20your%20organization%2C%20end%20users,where%20required%20by%20applicable%20law)). This can be integrated with government security monitoring systems for oversight and incident response. Other plans (Free, Plus, Team) do not provide organisation-level audit logs of user content, meaning those plans are less suited for regulated environments where auditing is required. A government agency evaluating ChatGPT will likely consider Enterprise the appropriate tier specifically due to this ability to log and review usage. OpenAI’s approach ensures that enterprises can meet their compliance obligations (e.g. maintaining records of AI interactions for auditing or freedom of information purposes) while still respecting user privacy in the default use of the tool.

## 6. Access Controls

Access control in ChatGPT pertains to how user accounts are managed, how permissions are set, and what mechanisms exist to authenticate users securely. Each plan (Free, Plus, Team, Enterprise) has a slightly different access control model:

- **Individual Accounts (Free/Plus):** Access to ChatGPT’s free or Plus service is tied to an individual OpenAI account (user registration is required with an email address, or via Google/Microsoft login). The user authenticates with a password or single sign-on from a provider. OpenAI supports **two-factor authentication (2FA)** for accounts – users can enable an extra OTP code via authenticator app for added login security (this is available to all users to protect their accounts). There are no roles or sharing in the free/Plus context; each account is isolated. Users must keep their own credentials secure and should not share accounts per the Terms of Use ([Terms of use | OpenAI](https://openai.com/policies/row-terms-of-use/#:~:text=your%20parent%20or%20legal%20guardian%E2%80%99s,permission%20to%20use%20the%20Services)). For government staff using Plus individually, this means each person would have their own login – there’s no administrative oversight of multiple accounts at this tier aside from any external identity management the agency might impose (e.g. requiring sign-in with a corporate Google account).

- **ChatGPT Team (Workspace):** The Team plan introduces a **dedicated workspace with multi-user support** ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=Easily%20manage%20your%20account)). One or more users are designated as administrators of the Team workspace. Admins can invite or remove team members and manage billing centrally. OpenAI provides an **admin console** for Team, which allows bulk user management (for example, adding a list of users all at once) and oversight of who has access ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=Easily%20manage%20your%20account)). Within a Team workspace, **user roles** can be assigned ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=,access%20with%20user%20roles)) – typically roles like *Admin* (with full management permissions) and *Member* (regular users who can only use ChatGPT but not manage others). Through these roles, an organisation can ensure only authorized people join the workspace and that at least two people have admin rights to manage it. All members of a Team have their own accounts (either new or existing OpenAI accounts that get linked to the Team). Authentication for Team members is the same as for individuals (email/password or SSO via Google/Microsoft, plus optional 2FA). Team admins cannot impersonate users or access their credentials; they can only control membership and view high-level usage. OpenAI also highlights the use of **Multi-Factor Authentication (MFA)** in Team to enhance security ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=Protect%20your%20data)) – presumably this refers to encouraging 2FA on accounts and possibly enforcing it for all team members (though enforcement would likely be a manual policy, as there’s no mention of admin-forced 2FA toggle). In summary, ChatGPT Team’s access control is about letting an organisation create a container of users with a couple of admin accounts overseeing membership.

- **ChatGPT Enterprise:** The Enterprise offering significantly upgrades access control and integration with enterprise identity systems. Firstly, Enterprise supports **Single Sign-On (SSO)** integration via SAML ([ChatGPT for enterprise | OpenAI](https://openai.com/chatgpt/enterprise/#:~:text=,data)). This means a government organisation can integrate ChatGPT with its internal identity provider (such as Azure Active Directory or Okta), allowing users to log in with their government credentials. SSO ensures that password policies and login processes align with the organisation’s standards, and it enables features like conditional access (e.g. only allow login from certain networks) and automatic de-provisioning. Alongside SSO, ChatGPT Enterprise supports **SCIM (System for Cross-domain Identity Management) provisioning** ([ChatGPT for enterprise | OpenAI](https://openai.com/chatgpt/enterprise/#:~:text=,data)). SCIM allows automatic provisioning and de-provisioning of user accounts: when a user joins or leaves the organisation (or changes roles), the identity management system can automatically create, update, or remove their ChatGPT Enterprise account. This is crucial for large-scale administration and ensures that only current employees have access at any given time, closing any gaps that could occur with manual user management. 

  Enterprise also features **domain verification** ([ChatGPT for enterprise | OpenAI](https://openai.com/chatgpt/enterprise/#:~:text=)) – the company can verify its email domain with OpenAI, so that only users with that email domain (e.g. `@gov.uk`) can join the workspace, and possibly to auto-enroll users who sign up with a company email into the organisation’s instance. This prevents random external sign-ups from accessing the Enterprise workspace and adds another layer of access restriction.

  In terms of roles and permissions, Enterprise offers **fine-grained access controls** beyond the basic admin/member split ([ChatGPT for enterprise | OpenAI](https://openai.com/chatgpt/enterprise/#:~:text=Administrative%20controls)). Admins can create groups and assign different permission levels, and also control feature access (for example, an admin could disable certain plugins or custom GPTs for regular users if desired) ([ChatGPT for enterprise | OpenAI](https://openai.com/chatgpt/enterprise/#:~:text=Administrative%20controls)). This allows tailoring ChatGPT’s functionality to the organisation’s policies. Additionally, an Enterprise admin console provides **user analytics** ([ChatGPT Pricing | OpenAI](https://openai.com/chatgpt/pricing/#:~:text=,user%20analytics%2C%20and%20GPT%20controls)) – the ability to see usage patterns, which users are active, etc., which indirectly is an access control tool (helping identify any abnormal usage that might indicate a compromised account).

  Like Team, Enterprise has centralized billing and user management, but it extends to full enterprise identity integration and granular controls. All data access is governed by these roles – and as mentioned in Audit Logging, admins have access to conversation logs through the compliance API if needed, which is a form of oversight not available in lower tiers.

**Summary of Access Controls:** Free and Plus are single-user services with basic account security features. Team provides *organizational accounts* with simple admin control over membership. Enterprise integrates with enterprise Identity and Access Management (IAM) systems, supporting SSO/SCIM, and provides admin tools for policy enforcement at scale ([ChatGPT Pricing | OpenAI](https://openai.com/chatgpt/pricing/#:~:text=,user%20analytics%2C%20and%20GPT%20controls)). Both Team and Enterprise ensure that **the organisation can control who has access to ChatGPT and what they can do** – for example, Enterprise admins could require all users to log in via the government’s secure login portal and automatically remove access for leavers, which is essential in a government setting.

From a UK security architecture standpoint, the Enterprise plan’s ability to integrate with existing identity providers is a big advantage, as it means ChatGPT can slot into the single sign-on ecosystem (possibly even behind government VPN or conditional access if configured) rather than being a standalone account system. Moreover, the presence of **multi-factor authentication** (either via OpenAI’s own account 2FA or through the organisation’s SSO which likely has MFA) meets the recommended practice for strong authentication, mitigating the risk of account compromise. 

OpenAI has also completed compliance audits on these aspects (user management, access control processes) under their SOC 2 report, which gives further confidence that their access control mechanisms are designed and operated securely ([Security | OpenAI](https://openai.com/security-and-privacy/#:~:text=OpenAI%20supports%20our%20customers%E2%80%99%20compliance,security%20controls%20and%20compliance%20activities)).

## 7. Compliance and Regulatory Requirements

OpenAI has made various compliance commitments for ChatGPT, particularly for the Team and Enterprise offerings, to assure customers (including public sector users) that the tool meets industry-standard security and privacy requirements. Below is a summary of relevant standards, certifications, and regulations that ChatGPT adheres to or supports:

- **SOC 2 Type II Certification:** ChatGPT’s business services (Team, Enterprise, and API) have undergone a SOC 2 Type 2 audit by an independent third party ([Security | OpenAI](https://openai.com/security-and-privacy/#:~:text=OpenAI%20supports%20our%20customers%E2%80%99%20compliance,security%20controls%20and%20compliance%20activities)). This audit evaluates the design and operating effectiveness of security controls in categories like Security and Confidentiality. Successfully completing SOC 2 Type II means OpenAI has demonstrated that it has robust processes to protect customer data over time. Government security reviewers often look for SOC 2 reports as evidence of good security practice. (OpenAI’s SOC 2 report is available under NDA via their trust portal ([Security | OpenAI](https://openai.com/security-and-privacy/#:~:text=Enterprise%2C%20ChatGPT%20Team%2C%20and%20ChatGPT,security%20controls%20and%20compliance%20activities)).)

- **CSA STAR Level 1:** OpenAI is listed in the Cloud Security Alliance’s Security, Trust, Assurance, and Risk (STAR) registry at Level 1 ([Security | OpenAI](https://openai.com/security-and-privacy/#:~:text=CSA%20STAR%20Level%201)). The CSA STAR registry is a publicly accessible registry where cloud providers document their security controls (often by responding to the CAIQ questionnaire). A Level 1 listing typically means OpenAI has self-assessed its ChatGPT product’s compliance with cloud security best practices and published those answers for transparency ([Security | OpenAI](https://openai.com/security-and-privacy/#:~:text=CSA%20STAR%20Level%201)). This is a good indicator that OpenAI is following industry best practices and allows customers to review their security posture in detail.

- **GDPR Compliance (EU and UK):** OpenAI affirms support for the EU General Data Protection Regulation (GDPR) and related privacy laws. For organisations subject to GDPR (which includes UK governmental bodies under UK GDPR law), OpenAI offers to sign a **Data Processing Addendum (DPA)** to ensure GDPR compliance ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Can%20OpenAI%20support%20my%20compliance,GDPR%20and%20other%20privacy%20laws)). The DPA contractually commits OpenAI to handle personal data in accordance with GDPR requirements (e.g. only processing it on documented instructions, ensuring adequate protections, assisting with data subject requests, etc.). With the introduction of the European data residency option (Section 4.1), OpenAI further addresses GDPR’s data transfer and localization concerns. OpenAI’s privacy notice and practices also align with principles of transparency, data minimization, and user control, which are key under GDPR. UK government adopters would likely execute a DPA with OpenAI and possibly a UK-specific addendum if needed, but the provision is there to support compliance. OpenAI explicitly mentions compliance with *“privacy laws, including the GDPR and CCPA”* on their security page ([Security | OpenAI](https://openai.com/security-and-privacy/#:~:text=Security%20compliance%20%26%20accreditation)), indicating their services are built with those regulations in mind. 

- **UK Data Protection Act & Public Sector Compliance:** While not explicitly named on OpenAI’s site, the UK Data Protection Act 2018 and UK GDPR are effectively covered by the GDPR compliance measures OpenAI has (since UK law is an implementation of GDPR principles). For UK government, additional frameworks like the NHS DSP Toolkit or ISO standards might be in consideration; OpenAI has not announced NHS-specific compliance yet, but its general security posture (SOC 2, etc.) provides a baseline. Government agencies would conduct their own Data Protection Impact Assessment (DPIA) when using ChatGPT, and OpenAI’s documentation (privacy policy, DPA, technical security measures) would feed into that.

- **CCPA:** For users in California or organisations needing to comply with the California Consumer Privacy Act, OpenAI indicates it supports CCPA compliance ([ChatGPT Pricing | OpenAI](https://openai.com/chatgpt/pricing/#:~:text=,user%20analytics%2C%20and%20GPT%20controls)). This is less directly relevant to UK users, but it shows OpenAI’s overall privacy compliance stance (CCPA is similar in spirit to GDPR for Californian residents’ data).

- **HIPAA (Healthcare) Compliance:** OpenAI mentions that for its business products, it is willing to sign **Business Associate Agreements (BAAs)** for HIPAA compliance when applicable ([Security | OpenAI](https://openai.com/security-and-privacy/#:~:text=OpenAI%20business%20products%20also%20support,visibility%20and%20fine%20grained%20controls)). This is specifically important if ChatGPT were to be used in a healthcare context (e.g. an NHS setting) where patient health information might be involved. A BAA is a legal requirement under HIPAA for any service processing Protected Health Information on behalf of a covered entity. By offering BAAs, OpenAI signals that it has appropriate safeguards for health data. While general government use might not involve HIPAA, this is noteworthy for any healthcare-related government bodies or use cases involving medical data.

- **Other Standards and Commitments:** OpenAI undergoes regular third-party **penetration testing** on ChatGPT business systems ([Security | OpenAI](https://openai.com/security-and-privacy/#:~:text=External%20testing)). This helps identify and remediate security vulnerabilities proactively. They also run a **bug bounty program** to encourage security researchers to report any security issues responsibly ([Security | OpenAI](https://openai.com/security-and-privacy/#:~:text=Reporting%20security%20issues)). These efforts aren’t formal certifications but demonstrate an active commitment to maintaining a strong security posture. Furthermore, OpenAI’s trust portal likely contains documentation of controls and perhaps mappings to frameworks like ISO 27001 or NIST, though those certifications have not been explicitly listed. There is no indication that ChatGPT is currently **FedRAMP** authorized (a U.S. government cloud standard) or equivalent, but the existing SOC 2 and CSA STAR compliance would cover many similar controls that UK officials care about.

In the context of UK government adoption, the key compliance takeaway is that **OpenAI has aligned ChatGPT with widely recognized security and privacy standards**. SOC 2 Type II gives assurance on security controls; GDPR compliance and DPAs address legal data protection requirements; and the availability of audit logs and encryption addresses many technical security requirements. OpenAI also notes that it supports customer compliance efforts for other regulatory needs and is open to contractual measures as needed ([Security | OpenAI](https://openai.com/security-and-privacy/#:~:text=OpenAI%20supports%20our%20customers%E2%80%99%20compliance,security%20controls%20and%20compliance%20activities)) ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Can%20OpenAI%20support%20my%20compliance,GDPR%20and%20other%20privacy%20laws)). 

Government policymakers and security analysts reviewing ChatGPT should still perform due diligence (e.g. review the SOC 2 audit report available on OpenAI’s trust portal ([Security | OpenAI](https://openai.com/security-and-privacy/#:~:text=OpenAI%20supports%20our%20customers%E2%80%99%20compliance,security%20controls%20and%20compliance%20activities)), and possibly seek ISO or other certifications if required by departmental policy), but the evidence so far suggests that ChatGPT Team and Enterprise are designed with compliance in mind. Notably, the alignment with **CSA STAR, SOC 2, GDPR, CCPA** and ability to sign **DPA/BAA** covers the fundamental areas typically required in risk assessments ([ChatGPT Pricing | OpenAI](https://openai.com/chatgpt/pricing/#:~:text=,user%20analytics%2C%20and%20GPT%20controls)) ([Security | OpenAI](https://openai.com/security-and-privacy/#:~:text=OpenAI%20business%20products%20also%20support,visibility%20and%20fine%20grained%20controls)). 

One should also keep an eye on evolving compliance: as of 2025, OpenAI is likely pursuing additional certifications (for example, ISO 27001 or perhaps UK-specific standards) to further reassure customers, and any UK government pilot or procurement would engage with OpenAI on those specifics. But at present, **ChatGPT’s compliance credentials are strong for a cloud service** – matching those of many established cloud SaaS providers – and there are concrete steps (like the DPA and EU residency) that OpenAI has taken to accommodate public sector needs ([OpenAI launches data residency in Europe | TechCrunch](https://techcrunch.com/2025/02/06/openai-launches-data-residency-in-europe/#:~:text=the%20AI%20company%E2%80%99s%20products)) ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Can%20OpenAI%20support%20my%20compliance,GDPR%20and%20other%20privacy%20laws)).

**Sources:**

- OpenAI, *ChatGPT Overview* – Official site description of ChatGPT’s purpose and features ([ChatGPT | OpenAI](https://openai.com/chatgpt/overview/#:~:text=Get%20answers,more%20productive)).  
- OpenAI, *ChatGPT Pricing & Plans* – Details on Free, Plus, Team, Enterprise features and pricing ([ChatGPT Pricing | OpenAI](https://openai.com/chatgpt/pricing/#:~:text=Team)) ([ChatGPT Pricing | OpenAI](https://openai.com/chatgpt/pricing/#:~:text=uploads%2C%20data%20analysis%2C%20and%20search)).  
- OpenAI, *New ways to manage your data in ChatGPT* (Apr 25, 2023) – Announcement of privacy controls like chat history toggle ([New ways to manage your data in ChatGPT | OpenAI](https://openai.com/index/new-ways-to-manage-your-data-in-chatgpt/#:~:text=We%27ve%20introduced%20the%20ability%20to,for%20abuse%2C%20before%20permanently%20deleting)) ([New ways to manage your data in ChatGPT | OpenAI](https://openai.com/index/new-ways-to-manage-your-data-in-chatgpt/#:~:text=We%20are%20also%20working%20on,available%20in%20the%20coming%20months)).  
- OpenAI Help Center, *Data Controls FAQ* – Instructions and effects of disabling chat history and exporting or deleting data ([Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq#:~:text=Our%20large%20language%20models%20are,you%20choose%20to%20disable%20training)) ([Data Controls FAQ | OpenAI Help Center](https://help.openai.com/en/articles/7730893-data-controls-faq#:~:text=Temporary%20Chats%20are%20deleted%20from,you%20have%20not%20opted%20out)).  
- OpenAI, *Terms of Use* (Dec 2024) – Terms governing individual use of ChatGPT ([Terms of use | OpenAI](https://openai.com/policies/row-terms-of-use/#:~:text=Thank%20you%20for%20using%20OpenAI%21)).  
- OpenAI, *Business Terms* (Nov 2023) – Terms for ChatGPT Enterprise/Team and API use ([Business terms | OpenAI](https://openai.com/policies/business-terms/#:~:text=These%20OpenAI%20Business%20Terms%20govern,the%20Terms%20of%20use%20%E2%81%A0)).  
- OpenAI, *Privacy Policy* – Explanation of data practices for OpenAI services ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Who%20owns%20inputs%20and%20outputs%3F)) ([ChatGPT](https://chatgpt.com/#team-pricing#:~:text=Voice)).  
- OpenAI, *Enterprise privacy FAQ* – OpenAI’s answers on data ownership, data retention and admin controls for ChatGPT Enterprise/Team ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Within%20your%20organization%2C%20end%20users,where%20required%20by%20applicable%20law)) ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=What%20is%20OpenAI%E2%80%99s%20policy%20on,ChatGPT%20Enterprise%20and%20ChatGPT%20Edu)).  
- TechCrunch, *OpenAI launches data residency in Europe* (Feb 6, 2025) – News on EU data center option for ChatGPT Enterprise ([OpenAI launches data residency in Europe | TechCrunch](https://techcrunch.com/2025/02/06/openai-launches-data-residency-in-europe/#:~:text=Beginning%20Thursday%2C%20OpenAI%20customers%20using,between%20networks%20or%20being%20accessed)) ([OpenAI launches data residency in Europe | TechCrunch](https://techcrunch.com/2025/02/06/openai-launches-data-residency-in-europe/#:~:text=OpenAI%20says%20that%2C%20with%20European,in%20the%20region%2C%20per%20OpenAI)). 
- OpenAI, *ChatGPT Team page* – Features of ChatGPT Team, including security and admin controls ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=,console%20and%20bulk%20member%20management)) ([ChatGPT Team | OpenAI](https://openai.com/chatgpt/team/#:~:text=%2A%20Multi)).  
- OpenAI, *ChatGPT Enterprise page* – Features of Enterprise, including security (SSO, encryption) and compliance offerings ([ChatGPT for enterprise | OpenAI](https://openai.com/chatgpt/enterprise/#:~:text=,data)) ([ChatGPT for enterprise | OpenAI](https://openai.com/chatgpt/enterprise/#:~:text=Administrative%20controls)).  
- OpenAI, *Security & Privacy* – OpenAI’s security compliance overview (SOC 2, GDPR, CCPA, CSA STAR) ([Security | OpenAI](https://openai.com/security-and-privacy/#:~:text=Security%20compliance%20%26%20accreditation)) ([Security | OpenAI](https://openai.com/security-and-privacy/#:~:text=CSA%20STAR%20Level%201)).  
- OpenAI, *Compliance API for Enterprise* – Documentation on audit logging via API for enterprise workspaces ([Enterprise privacy at OpenAI | OpenAI](https://openai.com/enterprise-privacy/#:~:text=Within%20your%20organization%2C%20end%20users,where%20required%20by%20applicable%20law)) ([Compliance API for Enterprise Customers | OpenAI Help Center](https://help.openai.com/en/articles/9261474-compliance-apis-for-enterprise-customers#:~:text=How%20it%20works)).